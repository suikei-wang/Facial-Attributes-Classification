{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run-in-once.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Bbc2c2--CrRG","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s2KlLYWzCxnH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595662471749,"user_tz":-600,"elapsed":690,"user":{"displayName":"Katerina Wang","photoUrl":"","userId":"04278788415983802632"}}},"source":["import os\n","import glob\n","import numpy as np\n","from matplotlib import pyplot\n","from PIL import Image"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Tx1HVq4GMzH","colab_type":"code","colab":{}},"source":["from zipfile import ZipFile \n","  \n","# specifying the zip file name \n","file_name = \"/content/drive/My Drive/8536_project/CelebA/Img/img_align_celeba.zip\"\n","  \n","# opening the zip file in READ mode \n","with ZipFile(file_name, 'r') as zip:  \n","    if os.path.isdir('img_align_celeba') == 0:\n","    # extracting all the files \n","      print('Extracting all the files now...') \n","      zip.extractall() \n","      print('Done!') \n","    else:\n","      print('File has already extracted.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMEcWkI3y-Wj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595662570332,"user_tz":-600,"elapsed":5652,"user":{"displayName":"Katerina Wang","photoUrl":"","userId":"04278788415983802632"}}},"source":["data_path = sorted(glob.glob('img_align_celeba/*.jpg'))\n","# print(len(data_path))\n","\n","label_path = \"/content/drive/My Drive/8536_project/CelebA/Anno/list_attr_celeba.txt\"\n","label_list = open(label_path).readlines()[2:]\n","data_label = []\n","for i in range(len(label_list)):\n","  data_label.append(label_list[i].split())\n","\n","for m in range(len(data_label)):\n","  data_label[m] = [n.replace('-1', '0') for n in data_label[m]][1:]\n","  data_label[m] = [int(p) for p in data_label[m]]\n","\n","attributes = open(label_path).readlines()[1].split()"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcWFU-6M0X2r","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595662572156,"user_tz":-600,"elapsed":648,"user":{"displayName":"Katerina Wang","photoUrl":"","userId":"04278788415983802632"}}},"source":["import torch\n","from torchvision import models\n","from torch.utils.data import Dataset, DataLoader\n","from torch import optim\n","from torch import nn\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as dataset\n","import torchvision.transforms as transforms\n","class celeba(Dataset):\n","  def __init__(self, data_path=None, label_path=None):\n","    self.data_path = data_path\n","    self.label_path = label_path\n","\n","    # Data transforms\n","    self.transform = transforms.Compose(\n","        [transforms.Resize(224),\n","         transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","   \n","  def __len__(self):\n","    return len(self.data_path)\n","  \n","  def __getitem__(self, idx):\n","    image_set = Image.open(self.data_path[idx])\n","    image_tensor = self.transform(image_set)\n","    image_label = torch.Tensor(self.label_path[idx])\n","\n","    return image_tensor, image_label\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ohSuKDU36uc","colab_type":"code","colab":{}},"source":["dataset = celeba(data_path, data_label)\n","# split data into train, valid, test set 7:2:1\n","indices = list(range(202599))\n","split_train = 141819\n","split_valid = 182339\n","train_idx, valid_idx, test_idx = indices[:split_train], indices[split_train:split_valid], indices[split_valid:]\n","\n","train_sampler = SubsetRandomSampler(train_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)\n","test_sampler = SubsetRandomSampler(test_idx)\n","\n","trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, sampler=train_sampler)\n","\n","validloader = torch.utils.data.DataLoader(dataset, sampler=valid_sampler)\n","\n","testloader =  torch.utils.data.DataLoader(dataset, sampler=test_sampler)\n","\n","print(len(trainloader))\n","print(len(validloader))\n","print(len(testloader))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ffhWRvryqIDD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595662574616,"user_tz":-600,"elapsed":703,"user":{"displayName":"Katerina Wang","photoUrl":"","userId":"04278788415983802632"}}},"source":["def train(model, epochs, train_all_losses, train_all_acc):\n","    model.train()\n","    # initial the running loss\n","    running_loss = 0.0\n","    # pick each data from trainloader i: batch index/ data: inputs and labels\n","    correct = 0\n","    for i, data in enumerate(trainloader):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        labels = torch.Tensor(labels)\n","        # print(type(labels))\n","        inputs = inputs.to('cuda')\n","        labels = labels.to('cuda')\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","        # forward + backward + optimize\n","        outputs = model(inputs)\n","        \n","        loss = criterion(outputs, labels)\n","        # print statistics\n","        running_loss += loss.item()\n","        # backpropagation\n","        loss.backward()\n","        # update parameters\n","        optimizer.step()\n","        \n","        result = outputs > 0.5\n","        correct += (result == labels).sum().item() \n","\n","        if i % 64 == 0: \n","            print('Training set: [Epoch: %d, Data: %6d] Loss: %.3f' %\n","                  (epochs + 1, i * 64, loss.item()))\n"," \n","    acc = correct / (split_train * 40)\n","    running_loss /= len(trainloader)\n","    train_all_losses.append(running_loss)\n","    train_all_acc.append(acc)\n","    print('\\nTraining set: Epoch: %d, Accuracy: %.2f %%' % (epochs + 1, 100. * acc))\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOsP96a2sceH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595662575749,"user_tz":-600,"elapsed":659,"user":{"displayName":"Katerina Wang","photoUrl":"","userId":"04278788415983802632"}}},"source":["def validation(model, val_all_losses, val_all_acc, best_acc):\n","    model.eval()\n","    validation_loss = 0.0\n","    correct = 0\n","    for data, target in validloader:\n","        data = data.to('cuda')\n","        target = target.to('cuda')\n","        output = model(data)\n","\n","        validation_loss += criterion(output, target).item()\n","\n","        result = output > 0.5\n","        correct += (result == target).sum().item()\n","\n","\n","    validation_loss /= len(validloader)\n","    acc = correct / (len(validloader) * 40)\n","\n","    val_all_losses.append(validation_loss)\n","    val_all_acc.append(acc)\n","\n","    \n","    print('\\nValidation set: Average loss: {:.3f}, Accuracy: {:.2f}%)\\n'\n","          .format(validation_loss, 100. * acc))\n","    \n","    return acc"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"AAtUlUzUVCGZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595662576908,"user_tz":-600,"elapsed":670,"user":{"displayName":"Katerina Wang","photoUrl":"","userId":"04278788415983802632"}}},"source":["def test(model, attr_acc, attr_name=attributes):\n","    test_loss = 0\n","    correct = 0\n","    pred = []\n","    for data, target in testloader:\n","        data = data.to('cuda')\n","        target = target.to('cuda')\n","        output = model(data)\n","        test_loss += criterion(output, target).item()\n","\n","        result = output > 0.5\n","        correct += (result == target).sum().item()\n","        compare = (result == target)\n","        pred.append(compare[0])\n","\n","\n","    test_loss /= len(testloader)\n","    acc = correct / (len(testloader) * 40)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n","        test_loss, 100. * acc))\n","    \n","    for m in range(len(attr_name)):\n","        num = 0\n","        for n in range(len(pred)):\n","            if pred[n][m]:\n","                num += 1\n","        accuracy = num / len(pred)\n","        attr_acc.append(accuracy)\n","\n","    for i in range(len(attr_acc)):\n","        print('Attribute: %s, Accuracy: %.3f' % (attr_name[i], attr_acc[i]))\n"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"_JdG7MfOsv-o","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595662577886,"user_tz":-600,"elapsed":554,"user":{"displayName":"Katerina Wang","photoUrl":"","userId":"04278788415983802632"}}},"source":["# mish activation function\n","class mish(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","    def forward(self, x):\n","        return x * (torch.tanh(F.softplus(x)))\n","\n","\n","\n","def conv_bn(inp, oup, stride):\n","    return nn.Sequential(\n","        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n","        nn.BatchNorm2d(oup),\n","        mish()\n","    )\n","\n","\n","def conv_dw(inp, oup, stride):\n","    return nn.Sequential(\n","        nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n","        nn.BatchNorm2d(inp),\n","        mish(),\n","    \n","        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n","        nn.BatchNorm2d(oup),\n","        mish()\n","    )\n","\n","\n","class MobileNet(nn.Module):\n","    def __init__(self):\n","        super(MobileNet, self).__init__()\n","\n","        self.features = nn.Sequential(\n","            conv_bn(  3,  32, 2), \n","            conv_dw( 32,  64, 1),\n","            conv_dw( 64, 128, 2),\n","            conv_dw(128, 128, 1),\n","            conv_dw(128, 256, 2),\n","            conv_dw(256, 256, 1),\n","            conv_dw(256, 512, 2),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 512, 1),\n","            conv_dw(512, 1024, 2),\n","            conv_dw(1024, 1024, 1),\n","            nn.AvgPool2d(7),\n","        )\n","\n","        self.fc = nn.Linear(1024, 40)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        x = torch.sigmoid(x)\n","        return x\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0l0oiRMUGtC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595662579110,"user_tz":-600,"elapsed":669,"user":{"displayName":"Katerina Wang","photoUrl":"","userId":"04278788415983802632"}}},"source":["# define empty list to store the losses and accuracy for ploting\n","train_all_losses2 = []\n","train_all_acc2 = []\n","val_all_losses2 = []\n","val_all_acc2 = []\n","test_all_losses2 = 0.0\n","# define the training epoches\n","epochs = 100"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"RiTwvIGzUHoB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595662580545,"user_tz":-600,"elapsed":1008,"user":{"displayName":"Katerina Wang","photoUrl":"","userId":"04278788415983802632"}}},"source":["# instantiate Net class\n","mobilenet = MobileNet()\n","# use cuda to train the network\n","mobilenet.to('cuda')\n","#loss function and optimizer\n","criterion = nn.BCELoss()\n","learning_rate = 1e-3\n","optimizer = torch.optim.Adam(mobilenet.parameters(), lr=learning_rate, betas=(0.9, 0.999))"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"Scp3U2dbUNIX","colab_type":"code","colab":{}},"source":["!pip install memory-profiler\n","%load_ext memory_profiler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KaWo3BRmUTo-","colab_type":"code","colab":{}},"source":["%%timeit\n","best_acc = 0.0\n","for epoch in range(epochs):\n","    train(mobilenet, epoch, train_all_losses2, train_all_acc2)\n","    acc = validation(mobilenet, val_all_losses2, val_all_acc2, best_acc)\n","    if acc > best_acc:\n","      checkpoint_path = './model_checkpoint.pth'\n","      best_acc = acc\n","      # save the model and optimizer\n","      torch.save({'model_state_dict': mobilenet.state_dict(),\n","              'optimizer_state_dict': optimizer.state_dict()}, checkpoint_path)\n","      print('new best model saved')\n","    print(\"========================================================================\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJ7QSP6qksqe","colab_type":"code","colab":{}},"source":["checkpoint_path = '/content/drive/My Drive/8536_project/model_checkpoint.pth'\n","model = MobileNet().to('cuda')\n","checkpoint = torch.load(checkpoint_path)\n","print(\"model load successfully.\")\n","\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","model.eval()\n","attr_acc = []\n","test(model, attr_acc=attr_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CbeLzqvvP_ra","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.figure(figsize=(8, 10))\n","plt.barh(range(40), [100 * acc for acc in attr_acc], tick_label = attributes, fc = 'brown')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OfjYDRcdTWwn","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8, 6))\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Loss')\n","plt.grid(True, linestyle='-.')\n","plt.plot(train_all_losses2, c='salmon', label = 'Training Loss')\n","plt.plot(val_all_losses2, c='brown', label = 'Validation Loss')\n","plt.legend(fontsize='12', loc='upper right')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CdubETrDTgZY","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8, 6))\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy')\n","plt.grid(True, linestyle='-.')\n","plt.plot(train_all_acc2, c='salmon', label = 'Training Accuracy')\n","plt.plot(val_all_acc2, c='brown', label = 'Validation Accuracy')\n","plt.legend(fontsize='12', loc='lower right')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ycG_Hd582In","colab_type":"code","colab":{}},"source":["# test images on the Model\n","transform = transforms.Compose(\n","        [transforms.Resize(224),\n","         transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","         \n","image_set = Image.open('/content/ourface1.png')\n","\n","image_tensor = transform(image_set)\n","image = torch.unsqueeze(image_tensor, 0)\n","image = image.to('cuda')\n","output = model(image)\n","result = output > 0.5\n","result = result.cpu().numpy()\n","\n","\n","for t in range(len(attributes)):\n","    if result[0][t] == True:\n","       print(\"Attribute: \\033[1;35m%s \\033[0m, \\033[1;35m%s \\033[0m\" % (attributes[t], result[0][t]))\n","    else:\n","       print(\"Attribute: %s, %s\" % (attributes[t], result[0][t]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sm4ueGkLkcZo","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}